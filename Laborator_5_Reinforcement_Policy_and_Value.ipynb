{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/valy3124/ML-Labs/blob/main/Laborator_5_Reinforcement_Policy_and_Value.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3a1x3D2pJlE"
      },
      "source": [
        "# Învățare Automată\n",
        "# Învățare prin Recompensă - rezolvarea proceselor de decizie Markov prin tehnici de programare dinamică (Value Iteration, Policy Iteration)\n",
        "### Autori:\n",
        "* Tudor Berariu - 2018\n",
        "* Alexandru Sorici - 2020"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6-C84FKpUfB"
      },
      "source": [
        "## 1. Scopul laboratorului"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTKbkxAwpYhl"
      },
      "source": [
        "Scopul laboratorului îl reprezintă înțelegerea conceptelor de proces markov de decizie (MDP), politică, valoare de stare, precum și implementarea unor metode de programare dinamică pentru rezolvarea problemei de control a unui MDP.\n",
        "\n",
        "În cadrul laboratorului veți:\n",
        "- implementa algoritmul de iterare a politicilor\n",
        "- implementa algoritmul de iterare a valorilor de stare"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8i_6oVDI-zp5"
      },
      "source": [
        "## 2. Workspace setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTs6cwy5_Na7"
      },
      "source": [
        "### Câteva bibioteci de care vom avea nevoie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "F6Y6WMfQ_R5L"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os.path\n",
        "from argparse import ArgumentParser\n",
        "from copy import copy\n",
        "from random import choice\n",
        "\n",
        "from typing import Dict, List, Tuple"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhMSc8oHEdLK"
      },
      "source": [
        "### Definirea unui labirint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "09ToJHh-Ef2S"
      },
      "outputs": [],
      "source": [
        "class Maze:\n",
        "\n",
        "    NORTH, EAST, SOUTH, WEST = 0, 1, 2, 3  # actions\n",
        "\n",
        "    DYNAMICS = {  # the stochastic effects of actions\n",
        "        NORTH: {(0, -1): 0.1, (-1, 0): .8, (0, 1): .1},\n",
        "        EAST: {(-1, 0): 0.1, (0, 1): .8, (1, 0): .1},\n",
        "        SOUTH: {(0, 1): 0.1, (1, 0): .8, (0, -1): .1},\n",
        "        WEST: {(1, 0): 0.1, (0, -1): .8, (-1, 0): .1},\n",
        "    }\n",
        "\n",
        "    WALL, EMPTY = \"x\", \" \"\n",
        "\n",
        "    VISUALS = {\n",
        "        (0, 0, 1, 1): \"\\N{BOX DRAWINGS HEAVY DOWN AND RIGHT}\",\n",
        "        (1, 0, 0, 1): \"\\N{BOX DRAWINGS HEAVY DOWN AND LEFT}\",\n",
        "        (1, 0, 1, 0): \"\\N{BOX DRAWINGS HEAVY HORIZONTAL}\",\n",
        "        (0, 1, 1, 0): \"\\N{BOX DRAWINGS HEAVY UP AND RIGHT}\",\n",
        "        (1, 1, 0, 0): \"\\N{BOX DRAWINGS HEAVY UP AND LEFT}\",\n",
        "        (0, 1, 0, 1): \"\\N{BOX DRAWINGS HEAVY VERTICAL}\",\n",
        "        (1, 1, 1, 1): \"\\N{BOX DRAWINGS HEAVY VERTICAL AND HORIZONTAL}\",\n",
        "        (1, 1, 1, 0): \"\\N{BOX DRAWINGS HEAVY UP AND HORIZONTAL}\",\n",
        "        (1, 1, 0, 1): \"\\N{BOX DRAWINGS HEAVY VERTICAL AND LEFT}\",\n",
        "        (1, 0, 1, 1): \"\\N{BOX DRAWINGS HEAVY DOWN AND HORIZONTAL}\",\n",
        "        (0, 1, 1, 1): \"\\N{BOX DRAWINGS HEAVY VERTICAL AND RIGHT}\",\n",
        "        (1, 0, 0, 0): \"\\N{BOX DRAWINGS HEAVY LEFT}\",\n",
        "        (0, 1, 0, 0): \"\\N{BOX DRAWINGS HEAVY UP}\",\n",
        "        (0, 0, 1, 0): \"\\N{BOX DRAWINGS HEAVY RIGHT}\",\n",
        "        (0, 0, 0, 1): \"\\N{BOX DRAWINGS HEAVY DOWN}\",\n",
        "        (0, 0, 0, 0): \"\\N{BOX DRAWINGS HEAVY VERTICAL AND HORIZONTAL}\",\n",
        "        WEST: \"\\N{LEFTWARDS ARROW}\",\n",
        "        NORTH: \"\\N{UPWARDS ARROW}\",\n",
        "        EAST: \"\\N{RIGHTWARDS ARROW}\",\n",
        "        SOUTH: \"\\N{DOWNWARDS ARROW}\",\n",
        "    }\n",
        "\n",
        "    def __init__(self, map_name):\n",
        "        self._rewards, self._cells = {}, []\n",
        "        with open(os.path.join(\"maps\", map_name), \"r\") as map_file:\n",
        "            for line in map_file.readlines():\n",
        "                if \":\" in line:\n",
        "                    name, value = line.strip().split(\":\")\n",
        "                    self._rewards[name] = float(value)\n",
        "                else:\n",
        "                    self._cells.append(list(line.strip()))\n",
        "        self._states = [(i, j) for i, row in enumerate(self._cells)\n",
        "                        for j, cell in enumerate(row) if cell != Maze.WALL]\n",
        "\n",
        "    @property\n",
        "    def actions(self):\n",
        "        return [Maze.NORTH, Maze.EAST, Maze.SOUTH, Maze.WEST]\n",
        "\n",
        "    @property\n",
        "    def states(self):\n",
        "        return copy(self._states)\n",
        "\n",
        "    def is_final(self, state):\n",
        "        row, col = state\n",
        "        return self._cells[row][col] != Maze.EMPTY\n",
        "\n",
        "    def effects(self, state, action):\n",
        "        if self.is_final(state):\n",
        "            return []\n",
        "        row, col = state\n",
        "        next_states = {}\n",
        "        for (d_row, d_col), prob in Maze.DYNAMICS[action].items():\n",
        "            next_row, next_col = row + d_row, col + d_col\n",
        "            if self._cells[next_row][next_col] == Maze.WALL:\n",
        "                next_row, next_col = row, col\n",
        "            if (next_row, next_col) in next_states:\n",
        "                prev_prob, _ = next_states[(next_row, next_col)]\n",
        "                prob += prev_prob\n",
        "            cell = self._cells[next_row][next_col]\n",
        "            reward = self._rewards[\"default\" if cell == Maze.EMPTY else cell]\n",
        "            next_states[(next_row, next_col)] = (prob, reward)\n",
        "        return [(s, p, r) for s, (p, r) in next_states.items()]\n",
        "\n",
        "    def print_policy(self, policy):\n",
        "        last_row = []\n",
        "        height = len(self._cells)\n",
        "\n",
        "        for row, row_cells in enumerate(self._cells):\n",
        "            width = len(row_cells)\n",
        "            for col, cell in enumerate(row_cells):\n",
        "                if cell == Maze.WALL:\n",
        "                    north, south, west, east = 0, 0, 0, 0\n",
        "                    if last_row and len(last_row) > col:\n",
        "                        north = last_row[col] == Maze.WALL\n",
        "                    if row + 1 < height:\n",
        "                        south = self._cells[row + 1][col] == Maze.WALL\n",
        "                    if col > 0:\n",
        "                        west = row_cells[col - 1] == Maze.WALL\n",
        "                    if col + 1 < width:\n",
        "                        east = row_cells[col + 1] == Maze.WALL\n",
        "                    sys.stdout.write(Maze.VISUALS[(west, north, east, south)])\n",
        "                elif self.is_final((row, col)):\n",
        "                    sys.stdout.write(cell)\n",
        "                else:\n",
        "                    action = policy[(row, col)]\n",
        "                    sys.stdout.write(Maze.VISUALS[action])\n",
        "            sys.stdout.write(\"\\n\")\n",
        "            last_row = row_cells\n",
        "        sys.stdout.flush()\n",
        "\n",
        "    def print_values(self, v):\n",
        "        for r, row_cells in enumerate(self._cells):\n",
        "            print(\" | \".join([\"%5.2f\" % v[(r, c)] if cell == Maze.EMPTY else \"     \"\n",
        "                              for c, cell in enumerate(row_cells)]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-G9p2SH-r0V"
      },
      "source": [
        "## Cerințe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "x1Od4ZRe2ksH"
      },
      "outputs": [],
      "source": [
        "MAP_NAME = 'complex'  #@param ['simple', 'complex', 'be_careful', 'suffer']\n",
        "gamma = 0.9 #@param {type: \"slider\", min: 0.0, max: 1.0, step: 0.1}\n",
        "max_delta = 1e-8 #@param {type:\"float\"}."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrvv3ZVH2ksI"
      },
      "source": [
        "### Cerința 1\n",
        "Implementați funcția **policy_iteration** pentru calculul politicii optime și a tabelului de utilitate așteptată pentru fiecare stare (celulă din grid) a labirintului."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "q6BL52zi2ksI"
      },
      "outputs": [],
      "source": [
        "def policy_iteration(game: Maze) -> Tuple[Dict[Tuple[int, int], int], Dict[Tuple[int, int], float]]:\n",
        "    v = {s: 0 for s in game.states}\n",
        "    policy = {s: choice(game.actions)\n",
        "              for s in game.states if not game.is_final(s)}\n",
        "    while True:\n",
        "\n",
        "      #Policy evaluation\n",
        "      while True:\n",
        "        delta = 0\n",
        "\n",
        "        for s in game.states:\n",
        "          if game.is_final(s):\n",
        "            continue\n",
        "\n",
        "          v_old = v[s]\n",
        "          v[s] = 0\n",
        "          for next_state, prob, reward in game.effects(s, policy[s]):\n",
        "            v[s] += prob * (reward + gamma * v[next_state])\n",
        "          delta = max(delta, abs(v_old - v[s]))\n",
        "\n",
        "        if delta < max_delta:\n",
        "          break\n",
        "\n",
        "      #Policy iteration\n",
        "      done = True\n",
        "\n",
        "      for s in game.states:\n",
        "        if game.is_final(s):\n",
        "          continue\n",
        "\n",
        "        old_action = policy[s]\n",
        "        max_action = float('-inf')\n",
        "\n",
        "        for action in game.actions:\n",
        "          action_value = 0\n",
        "          for next_state, prob, reward in game.effects(s, action):\n",
        "            action_value += prob * (reward + gamma * v[next_state])\n",
        "          if action_value > max_action:\n",
        "            max_action = action_value\n",
        "            policy[s] = action\n",
        "\n",
        "        if old_action != policy[s]:\n",
        "          done = False\n",
        "\n",
        "      if done:\n",
        "        break\n",
        "    return policy, v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANyjNM_i2ksJ"
      },
      "source": [
        "### Cerința 2\n",
        "Implementați funcția **value_iteration** pentru calculul politicii optime și a tabelului de utilitate așteptată pentru fiecare stare (celulă din grid) a labirintului."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Lucs8IAS2ksK"
      },
      "outputs": [],
      "source": [
        "def value_iteration(game: Maze) -> Tuple[Dict[Tuple[int, int], int], Dict[Tuple[int, int], float]]:\n",
        "    v = {s: 0 for s in game.states}\n",
        "    policy = {s: choice(game.actions)\n",
        "              for s in game.states if not game.is_final(s)}\n",
        "\n",
        "    while True:\n",
        "        delta = 0\n",
        "\n",
        "        for s in game.states:\n",
        "          if game.is_final(s):\n",
        "            continue\n",
        "\n",
        "          v_old = v[s]\n",
        "          best_action = float('-inf')\n",
        "          for action in game.actions:\n",
        "            for next_state, prob, reward in game.effects(s, action):\n",
        "              if prob * (reward + gamma * v[next_state]) > best_action:\n",
        "                best_action = prob * (reward + gamma * v[next_state])\n",
        "\n",
        "          delta = max(delta, abs(v[s] - best_action))\n",
        "          v[s] = best_action\n",
        "\n",
        "        if delta < max_delta:\n",
        "          break\n",
        "\n",
        "    for s in game.states:\n",
        "      if game.is_final(s):\n",
        "        continue\n",
        "\n",
        "      max_action = float('-inf')\n",
        "      for action in game.actions:\n",
        "        action_value = 0\n",
        "        for next_state, prob, reward in game.effects(s, action):\n",
        "          action_value += prob * (reward + gamma * v[next_state])\n",
        "          if action_value > max_action:\n",
        "            max_action = action_value\n",
        "            policy[s] = action\n",
        "\n",
        "    return policy, v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6CoJAktMV_I"
      },
      "source": [
        "## Evaluare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDueFUXSMUwL",
        "outputId": "3a4340bb-66a2-4060-89f3-493060feb8f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Policy iteration:\n",
            "      |       |       |       |       |       |       |       |       |       |       |       |      \n",
            "      |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |       |      \n",
            "      |       |       |       |       |       |       |       |       |       |       |  0.00 |  0.00 |       |       |       |       |       |      \n",
            "      |       |  0.80 |  0.58 |  0.41 |  0.30 |  0.25 |       |       |       |       |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |      \n",
            "      |       |       |       |       |       |  0.18 |       |       |       |       |       |       |       |       |       |       |  0.00 |      \n",
            "      |       |       |       |       |       |  0.14 |  0.10 |  0.07 |  0.05 |  0.04 |  0.03 |  0.02 |  0.01 |  0.01 |  0.01 |  0.01 |  0.00 |      \n",
            "      |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |      \n",
            "┏━━━━━━━━━━━┓\n",
            "┃↑→→→→→→→→→↓┗┓\n",
            "┃A╺━━━━┳┳┳┓↓↓┗━━━━┓\n",
            "┃B←←←←←┣╋╋┫→→→→→→↓┃\n",
            "┣┳┳┳┳┓↑┗┻┻┻━━━━━╸↓┃\n",
            "┣╋╋╋╋┫↑←←←←←←←←←←←┃\n",
            "┗┻┻┻┻┻━━━━━━━━━━━━┛\n",
            "Value iteration:\n",
            "      |       |       |       |       |       |       |       |       |       |       |       |      \n",
            "      |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |       |      \n",
            "      |       |       |       |       |       |       |       |       |       |       |  0.00 |  0.00 |       |       |       |       |       |      \n",
            "      |       |  0.80 |  0.58 |  0.41 |  0.30 |  0.21 |       |       |       |       |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |      \n",
            "      |       |       |       |       |       |  0.15 |       |       |       |       |       |       |       |       |       |       |  0.00 |      \n",
            "      |       |       |       |       |       |  0.11 |  0.08 |  0.06 |  0.04 |  0.03 |  0.02 |  0.02 |  0.01 |  0.01 |  0.01 |  0.00 |  0.00 |      \n",
            "      |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |      \n",
            "┏━━━━━━━━━━━┓\n",
            "┃→→→→→→→→→→↓┗┓\n",
            "┃A╺━━━━┳┳┳┓↓↓┗━━━━┓\n",
            "┃B←←←←←┣╋╋┫→→→→→→↓┃\n",
            "┣┳┳┳┳┓↑┗┻┻┻━━━━━╸↓┃\n",
            "┣╋╋╋╋┫↑←←←←←←←←←←←┃\n",
            "┗┻┻┻┻┻━━━━━━━━━━━━┛\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "\n",
        "game = Maze(MAP_NAME)\n",
        "\n",
        "print(\"Policy iteration:\")\n",
        "policy, v = policy_iteration(game)\n",
        "game.print_values(v)\n",
        "game.print_policy(policy)\n",
        "\n",
        "print(\"Value iteration:\")\n",
        "policy, v = value_iteration(game)\n",
        "game.print_values(v)\n",
        "game.print_policy(policy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "A9cIM3B22ksL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}